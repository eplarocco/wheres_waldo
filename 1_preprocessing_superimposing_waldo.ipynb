{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Wheres Waldo?\n",
    "### Name: Eileanor LaRocco\n",
    "In this assignment, you will develop an object detection algorithm to locate Waldo in a set of images. You will develop a model to detect the bounding box around Waldo. Your final task is to submit your predictions on Kaggle for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process/Issues\n",
    "- Double-checked that the images we were given were correctly bounded (did this by visualizing the boxes on the images - they look good!)\n",
    "- Complication: Originally when I creating augmented images, the bounding box labels did not also augment. I also had to try out a few types of augmentation to see what made sense for waldo. The augmented images may still not be as different from one another as they could be which could allow the model to favor the training images that occur more frequently.\n",
    "- Complication: Similarly, when resizing the images, ensuring the bounding boxes not only are also adjusted if necessary, but ensuring they do not get cut off and the image is not stretched/shrunk too much.\n",
    "- Tried Yolo architecture first but produced too many boxes and did not work well. Tried faster rcnn architecture next and the inputs and outputs and processing steps for each were very different which was frustrating\n",
    "- Checking that the bounding boxes are updating with image resizing/cropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = device = torch.device(\"cuda\") #mps\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading 2024-fall-ml-3-hw-4-wheres-waldo.zip to ./2024-fall-ml-3-hw-4-wheres-waldo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38.2M/38.2M [00:01<00:00, 31.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting archive ./2024-fall-ml-3-hw-4-wheres-waldo/2024-fall-ml-3-hw-4-wheres-waldo.zip to ./2024-fall-ml-3-hw-4-wheres-waldo\n"
     ]
    }
   ],
   "source": [
    "od.download('https://www.kaggle.com/competitions/2024-fall-ml-3-hw-4-wheres-waldo/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"2024-fall-ml-3-hw-4-wheres-waldo/train/train\" # Original Train Images\n",
    "test_folder = \"2024-fall-ml-3-hw-4-wheres-waldo/test/test\" # Original Test Images\n",
    "annotations_file = \"2024-fall-ml-3-hw-4-wheres-waldo/annotations.csv\" # Original Annotations File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check size of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 8.jpg, Width: 2800, Height: 1760\n",
      "Image: 9.jpg, Width: 1298, Height: 951\n",
      "Image: 14.jpg, Width: 1700, Height: 2340\n",
      "Image: 15.jpg, Width: 1600, Height: 1006\n",
      "Image: 17.jpg, Width: 1599, Height: 1230\n",
      "Image: 16.jpg, Width: 1525, Height: 3415\n",
      "Image: 12.jpg, Width: 1276, Height: 1754\n",
      "Image: 13.jpg, Width: 1280, Height: 864\n",
      "Image: 11.jpg, Width: 2828, Height: 1828\n",
      "Image: 10.jpg, Width: 1600, Height: 980\n",
      "Image: 21.jpg, Width: 2048, Height: 1515\n",
      "Image: 20.jpg, Width: 2953, Height: 2088\n",
      "Image: 22.jpg, Width: 500, Height: 256\n",
      "Image: 23.jpg, Width: 325, Height: 300\n",
      "Image: 27.jpg, Width: 591, Height: 629\n",
      "Image: 26.jpg, Width: 600, Height: 374\n",
      "Image: 18.jpg, Width: 1590, Height: 981\n",
      "Image: 24.jpg, Width: 456, Height: 256\n",
      "Image: 25.jpg, Width: 413, Height: 500\n",
      "Image: 19.jpg, Width: 1280, Height: 864\n",
      "Image: 4.jpg, Width: 2048, Height: 1272\n",
      "Image: 5.jpg, Width: 2100, Height: 1760\n",
      "Image: 7.jpg, Width: 1949, Height: 1419\n",
      "Image: 6.jpg, Width: 2048, Height: 1454\n",
      "Image: 2.jpg, Width: 1286, Height: 946\n",
      "Image: 3.jpg, Width: 2048, Height: 1346\n",
      "Image: 1.jpg, Width: 2048, Height: 1251\n"
     ]
    }
   ],
   "source": [
    "# Train Images\n",
    "\n",
    "# Iterate over all images in the folder\n",
    "for image_name in os.listdir(train_folder):\n",
    "    if image_name.endswith((\".jpg\")):\n",
    "        image_path = os.path.join(train_folder, image_name)\n",
    "        \n",
    "        # Read the image using OpenCV\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            height, width, channels = img.shape  # Get image size (height, width, channels)\n",
    "            print(f\"Image: {image_name}, Width: {width}, Height: {height}\")\n",
    "        else:\n",
    "            print(f\"Could not read image: {image_name}\")\n",
    "\n",
    "#Image 27 includes waldo 6 times, 10 2 times, 8 2 times\n",
    "#16,22-27 do not include waldo in a background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 8.jpg, Width: 2800, Height: 1760\n",
      "Image: 9.jpg, Width: 1298, Height: 951\n",
      "Image: 4.jpg, Width: 2048, Height: 1272\n",
      "Image: 5.jpg, Width: 2100, Height: 1760\n",
      "Image: 7.jpg, Width: 1949, Height: 1419\n",
      "Image: 6.jpg, Width: 2048, Height: 1454\n",
      "Image: 2.jpg, Width: 1286, Height: 946\n",
      "Image: 3.jpg, Width: 2048, Height: 1346\n",
      "Image: 1.jpg, Width: 2048, Height: 1251\n"
     ]
    }
   ],
   "source": [
    "# Test Images\n",
    "\n",
    "# Iterate over all images in the folder\n",
    "for image_name in os.listdir(test_folder):\n",
    "    if image_name.endswith((\".jpg\")):\n",
    "        image_path = os.path.join(train_folder, image_name)\n",
    "        \n",
    "        # Read the image using OpenCV\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            height, width, channels = img.shape  # Get image size (height, width, channels)\n",
    "            print(f\"Image: {image_name}, Width: {width}, Height: {height}\")\n",
    "        else:\n",
    "            print(f\"Could not read image: {image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw bounding boxes on each training image to check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/1.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/10.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/11.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/12.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/13.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/14.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/15.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/17.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/18.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/19.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/2.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/3.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/4.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/5.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/6.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/7.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/8.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/9.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/8.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/10.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/16.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/20.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/21.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/22.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/23.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/24.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/25.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/26.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/27.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/27.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/27.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/27.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/27.jpg\n",
      "Annotated image saved to 2024-fall-ml-3-hw-4-wheres-waldo/checks/27.jpg\n",
      "All bounding boxes have been drawn and saved.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "output_folder = \"2024-fall-ml-3-hw-4-wheres-waldo/checks\"  # Folder to save images with drawn boxes\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read the CSV file\n",
    "# Assumes the CSV columns are: filename, xmin, ymin, xmax, ymax\n",
    "annotations = pd.read_csv(annotations_file)\n",
    "\n",
    "# Iterate through each image in the annotations\n",
    "for _, row in annotations.iterrows():\n",
    "    image_name = row[\"filename\"]\n",
    "    x_min, y_min, x_max, y_max = row[\"xmin\"], row[\"ymin\"], row[\"xmax\"], row[\"ymax\"]\n",
    "    \n",
    "    # Load the image\n",
    "    image_path = os.path.join(train_folder, image_name)\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} not found. Skipping...\")\n",
    "        continue\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Draw the bounding box\n",
    "    # cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (B, G, R), thickness)\n",
    "    cv2.rectangle(image, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 4)\n",
    "    \n",
    "    # Optionally, add a label or text\n",
    "    label = \"Waldo\"\n",
    "    cv2.putText(image, label, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Save the image\n",
    "    output_path = os.path.join(output_folder, image_name)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "    print(f\"Annotated image saved to {output_path}\")\n",
    "\n",
    "print(\"All bounding boxes have been drawn and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Waldo Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture each waldo bounding box and save to waldo folder to create set of waldos\n",
    "\n",
    "# Define the paths\n",
    "image_folder = train_folder\n",
    "csv_path = annotations_file\n",
    "output_folder = \"2024-fall-ml-3-hw-4-wheres-waldo/train/waldo\"\n",
    "\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read the CSV file\n",
    "with open(csv_path, mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)  # Use DictReader for column names\n",
    "    counter = 1\n",
    "\n",
    "    for row in csv_reader:\n",
    "        # Extract information from the CSV\n",
    "        filename = row[\"filename\"]\n",
    "        x_min = int(row[\"xmin\"])\n",
    "        y_min = int(row[\"ymin\"])\n",
    "        x_max = int(row[\"xmax\"])\n",
    "        y_max = int(row[\"ymax\"])\n",
    "\n",
    "        base, ext = os.path.splitext(filename)  # Split filename into base and extension\n",
    "        counter += 1\n",
    "\n",
    "        # Construct the full path to the image\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        # Check if the image exists\n",
    "        if os.path.exists(image_path):\n",
    "            with Image.open(image_path) as img:\n",
    "                # Crop the image using bounding box coordinates\n",
    "                cropped_img = img.crop((x_min, y_min, x_max, y_max))\n",
    "\n",
    "                # Save the cropped image\n",
    "                if os.path.exists(os.path.join(output_folder, f\"cropped_{filename}\")):\n",
    "                    filename = f\"{base}_{counter}{ext}\"  # Add suffix to filename\n",
    "                    #counter += 1\n",
    "                    output_path = os.path.join(output_folder, f\"cropped_{filename}\")\n",
    "                    cropped_img.save(output_path)\n",
    "                else:\n",
    "                    output_path = os.path.join(output_folder, f\"cropped_{filename}\")\n",
    "                    cropped_img.save(output_path)\n",
    "        else:\n",
    "            print(f\"Warning: {filename} not found in {image_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Background\n",
    "from rembg import remove\n",
    "import cv2\n",
    "\n",
    "input_path = \"2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_24.jpg\"\n",
    "output_path = \"2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_24_no_background.png\"\n",
    "\n",
    "# Processing the image \n",
    "input = Image.open(input_path) \n",
    "  \n",
    "# Removing the background from the given Image \n",
    "output = remove(input) \n",
    "  \n",
    "#Saving the image in the given path \n",
    "output.save(output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_16.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_15.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_8_20.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_10.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_10_21.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_13.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_25.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_19.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_24.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_26.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/waldo/cropped_27_35.jpg\n"
     ]
    }
   ],
   "source": [
    "### Remove Waldo images that are wonky (too big) (too small - 19, 15, 13, 10)\n",
    "\n",
    "def delete_files_from_list(folder_path, file_names_to_delete):\n",
    "    \"\"\"Deletes files in the given folder if their name is in the provided list.\"\"\"\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename in file_names_to_delete:\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path =  \"2024-fall-ml-3-hw-4-wheres-waldo/train/waldo\"\n",
    "    file_names_to_delete = [\"cropped_8_20.jpg\", \"cropped_10_21.jpg\", \"cropped_16.jpg\", \"cropped_24.jpg\", \"cropped_25.jpg\", \"cropped_26.jpg\", \"cropped_27_35.jpg\", \"cropped_19.jpg\", \"cropped_15.jpg\", \"cropped_13.jpg\", \"cropped_10.jpg\"]\n",
    "    delete_files_from_list(folder_path, file_names_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/train/16.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/train/22.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/train/23.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/train/27.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/train/26.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/train/24.jpg\n",
      "Deleted: 2024-fall-ml-3-hw-4-wheres-waldo/train/train/25.jpg\n"
     ]
    }
   ],
   "source": [
    "#Exclude no-busy-background images as they don't appear in the test set (16, 22-27)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = train_folder\n",
    "    file_names_to_delete = [\"16.jpg\", \"22.jpg\", \"23.jpg\", \"24.jpg\", \"25.jpg\", \"26.jpg\", \"27.jpg\"]\n",
    "    delete_files_from_list(folder_path, file_names_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: cropped_24_no_background.png, Width: 169, Height: 176\n",
      "Image: cropped_6.jpg, Width: 39, Height: 44\n",
      "Image: cropped_17.jpg, Width: 21, Height: 31\n",
      "Image: cropped_7.jpg, Width: 35, Height: 48\n",
      "Image: cropped_5.jpg, Width: 31, Height: 40\n",
      "Image: cropped_14.jpg, Width: 40, Height: 41\n",
      "Image: cropped_4.jpg, Width: 23, Height: 27\n",
      "Image: cropped_11.jpg, Width: 22, Height: 27\n",
      "Image: cropped_1.jpg, Width: 37, Height: 49\n",
      "Image: cropped_3.jpg, Width: 32, Height: 37\n",
      "Image: cropped_12.jpg, Width: 32, Height: 46\n",
      "Image: cropped_2.jpg, Width: 25, Height: 33\n",
      "Image: cropped_23.jpg, Width: 41, Height: 50\n",
      "Image: cropped_22.jpg, Width: 39, Height: 47\n",
      "Image: cropped_20.jpg, Width: 41, Height: 51\n",
      "Image: cropped_21.jpg, Width: 29, Height: 32\n",
      "Image: cropped_9.jpg, Width: 30, Height: 34\n",
      "Image: cropped_18.jpg, Width: 31, Height: 36\n",
      "Image: cropped_8.jpg, Width: 25, Height: 31\n",
      "Image: cropped_27.jpg, Width: 25, Height: 28\n",
      "Image: cropped_27_31.jpg, Width: 30, Height: 37\n",
      "Image: cropped_27_32.jpg, Width: 30, Height: 33\n",
      "Image: cropped_27_33.jpg, Width: 30, Height: 32\n",
      "Image: cropped_27_34.jpg, Width: 27, Height: 33\n"
     ]
    }
   ],
   "source": [
    "# Waldo Images\n",
    "\n",
    "# Iterate over all images in the folder\n",
    "for image_name in os.listdir(\"2024-fall-ml-3-hw-4-wheres-waldo/train/waldo\"):\n",
    "    if image_name.endswith((\".jpg\", \".png\")):\n",
    "        image_path = os.path.join(\"2024-fall-ml-3-hw-4-wheres-waldo/train/waldo\", image_name)\n",
    "        \n",
    "        # Read the image using OpenCV\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            height, width, channels = img.shape  # Get image size (height, width, channels)\n",
    "            print(f\"Image: {image_name}, Width: {width}, Height: {height}\")\n",
    "        else:\n",
    "            print(f\"Could not read image: {image_name}\")\n",
    "\n",
    "#Image 27 includes waldo 6 times, 10 2 times, 8 2 times\n",
    "#16,22-27 do not include waldo in a background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Define the paths\n",
    "input_folder = train_folder\n",
    "overlay_folder = \"2024-fall-ml-3-hw-4-wheres-waldo/train/waldo\"\n",
    "output_folder = \"2024-fall-ml-3-hw-4-wheres-waldo/train/chunks\"\n",
    "csv_path = \"2024-fall-ml-3-hw-4-wheres-waldo/train/annotations_chunks.csv\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "chunk_size = 512  # Crop size\n",
    "num_crops_per_image = 40  # Number of random crops per image\n",
    "min_overlay_size = (20, 20)  # Maximum size of overlay (width, height)\n",
    "max_overlay_size = (25, 25)  # Maximum size of overlay (width, height)\n",
    "\n",
    "# Function to check if an image is padded\n",
    "def is_padded(image):\n",
    "    # Assuming padded areas are transparent or uniform\n",
    "    return image.getbbox() is None  # None means the image is completely uniform (padded)\n",
    "\n",
    "# Function to resize overlay with minimum and maximum constraints\n",
    "def resize_overlay(overlay, min_size, max_size):\n",
    "    # Ensure the overlay respects the maximum size\n",
    "    overlay.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Check if the overlay is smaller than the minimum size\n",
    "    if overlay.width < min_size[0] or overlay.height < min_size[1]:\n",
    "        # Resize explicitly to the minimum size while maintaining aspect ratio\n",
    "        overlay = overlay.resize(min_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    return overlay\n",
    "\n",
    "# Open the CSV file for saving bounding box annotations\n",
    "with open(csv_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    # Write header\n",
    "    csv_writer.writerow([\"filename\", \"x_min\", \"y_min\", \"x_max\", \"y_max\"])\n",
    "\n",
    "    # Get the list of image files\n",
    "    large_images = [\n",
    "        os.path.join(input_folder, f)\n",
    "        for f in os.listdir(input_folder)\n",
    "        if f.endswith('.jpg')\n",
    "    ]\n",
    "    smaller_images = [\n",
    "        os.path.join(overlay_folder, f)\n",
    "        for f in os.listdir(overlay_folder)\n",
    "        if f.endswith('.png')\n",
    "    ]\n",
    "\n",
    "    # Process each large image\n",
    "    for img_idx, large_image_path in enumerate(large_images):\n",
    "        with Image.open(large_image_path) as img:\n",
    "            img = img.convert(\"RGBA\")  # Ensure RGBA mode for transparency\n",
    "\n",
    "            # Skip padded images\n",
    "            if is_padded(img):\n",
    "                print(f\"Skipping padded image: {large_image_path}\")\n",
    "                continue\n",
    "\n",
    "            width, height = img.size\n",
    "\n",
    "            # Perform multiple random crops\n",
    "            for crop_idx in range(num_crops_per_image):\n",
    "                # Random crop coordinates\n",
    "                top = random.randint(0, height - chunk_size)\n",
    "                left = random.randint(0, width - chunk_size)\n",
    "                box = (left, top, left + chunk_size, top + chunk_size)\n",
    "                chunk = img.crop(box)\n",
    "\n",
    "                # Randomly select a smaller image (overlay)\n",
    "                overlay_path = random.choice(smaller_images)\n",
    "                try:\n",
    "                    with Image.open(overlay_path) as overlay:\n",
    "                        overlay = overlay.convert(\"RGBA\")  # Ensure RGBA mode\n",
    "\n",
    "                        # Resize overlay to fit within the crop\n",
    "                        overlay = resize_overlay(overlay, min_overlay_size, max_overlay_size)\n",
    "\n",
    "                        # Random position for overlay within the chunk\n",
    "                        overlay_x = random.randint(0, chunk_size - overlay.width)\n",
    "                        overlay_y = random.randint(0, chunk_size - overlay.height)\n",
    "\n",
    "                        # Superimpose the overlay onto the chunk\n",
    "                        chunk.paste(overlay, (overlay_x, overlay_y), overlay)\n",
    "\n",
    "                        # Calculate bounding box for the overlay\n",
    "                        x_min = overlay_x  # Global x_min relative to the original image\n",
    "                        y_min = overlay_y   # Global y_min relative to the original image\n",
    "                        x_max = overlay_x + overlay.width  # Global x_max\n",
    "                        y_max = overlay_y + overlay.height  # Global y_max\n",
    "\n",
    "                        # Save bounding box to CSV\n",
    "                        output_filename = f\"chunk_{img_idx}_{crop_idx}.jpg\"\n",
    "                        csv_writer.writerow([output_filename, x_min, y_min, x_max, y_max])\n",
    "\n",
    "                        # Save the resulting 128x128 image\n",
    "                        output_path = os.path.join(output_folder, output_filename)\n",
    "                        chunk.convert(\"RGB\").save(output_path, \"JPEG\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing overlay {overlay_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All bounding boxes have been drawn and saved.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "output_folder = \"2024-fall-ml-3-hw-4-wheres-waldo/checks\"  # Folder to save images with drawn boxes\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read the CSV file\n",
    "# Assumes the CSV columns are: filename, xmin, ymin, xmax, ymax\n",
    "annotations = pd.read_csv(\"2024-fall-ml-3-hw-4-wheres-waldo/train/annotations_chunks.csv\")\n",
    "\n",
    "# Iterate through each image in the annotations\n",
    "for _, row in annotations.iterrows():\n",
    "    image_name = row[\"filename\"]\n",
    "    x_min, y_min, x_max, y_max = row[\"x_min\"], row[\"y_min\"], row[\"x_max\"], row[\"y_max\"]\n",
    "    \n",
    "    # Load the image\n",
    "    image_path = os.path.join(\"2024-fall-ml-3-hw-4-wheres-waldo/train/chunks\", image_name)\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} not found. Skipping...\")\n",
    "        continue\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Draw the bounding box\n",
    "    # cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (B, G, R), thickness)\n",
    "    cv2.rectangle(image, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 4)\n",
    "    \n",
    "    # Optionally, add a label or text\n",
    "    label = \"Waldo\"\n",
    "    cv2.putText(image, label, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Save the image\n",
    "    output_path = os.path.join(output_folder, image_name)\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "    #print(f\"Annotated image saved to {output_path}\")\n",
    "\n",
    "print(\"All bounding boxes have been drawn and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into train and validation sets\n",
    "annotations = pd.read_csv(\"2024-fall-ml-3-hw-4-wheres-waldo/train/annotations_chunks.csv\")\n",
    "image_files = annotations[\"filename\"].unique()\n",
    "train_images, val_images = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "def filter_csv_by_column(input_csv, output_csv, column_name, values_list):\n",
    "\n",
    "    # Load the CSV into a DataFrame\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    filtered_df = df[df[column_name].isin(values_list)]\n",
    "\n",
    "    # Save the filtered DataFrame to a new CSV file\n",
    "    filtered_df.to_csv(output_csv, index=False)\n",
    "\n",
    "#Train Annotations\n",
    "values_list = list(train_images)\n",
    "output_csv = \"2024-fall-ml-3-hw-4-wheres-waldo/train_annotations.csv\"\n",
    "column_name = \"filename\"\n",
    "filter_csv_by_column(\"2024-fall-ml-3-hw-4-wheres-waldo/train/annotations_chunks.csv\", output_csv, column_name, values_list)\n",
    "\n",
    "#Test Annotations\n",
    "values_list = list(val_images)\n",
    "output_csv = \"2024-fall-ml-3-hw-4-wheres-waldo/test_annotations.csv\"\n",
    "column_name = \"filename\"\n",
    "filter_csv_by_column(\"2024-fall-ml-3-hw-4-wheres-waldo/train/annotations_chunks.csv\", output_csv, column_name, values_list)\n",
    "\n",
    "#Train/Test Split (80/20)\n",
    "def split_directory(source_dir, target_dir, file_list):\n",
    "    \"\"\"Splits files from source_dir to target_dir based on file_list.\"\"\"\n",
    "\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    for file_name in file_list:\n",
    "        source_path = os.path.join(source_dir, file_name)\n",
    "        target_path = os.path.join(target_dir, file_name)\n",
    "\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.move(source_path, target_path)\n",
    "            #print(f\"Moved: {file_name}\")\n",
    "        else:\n",
    "            print(f\"File not found: {file_name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    source_dir = \"2024-fall-ml-3-hw-4-wheres-waldo/train/chunks\"\n",
    "    target_dir = \"2024-fall-ml-3-hw-4-wheres-waldo/train/val\"\n",
    "    file_list = list(val_images)\n",
    "\n",
    "    split_directory(source_dir, target_dir, file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
